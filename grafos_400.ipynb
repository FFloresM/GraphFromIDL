{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string, re\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens(texto):\n",
    "    \"\"\"Retorna una lista con los tokens de texto\"\"\"\n",
    "    texto = texto.lower() #convevrtir a minuscula\n",
    "    texto = re.sub(r'\\d+', '', texto)\n",
    "    texto = texto.translate(str.maketrans('','', string.punctuation)) #eliminar puntuacion\n",
    "    #texto = texto.strip() #remove whitspaces at begin and end\n",
    "    return word_tokenize(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#falta ignorar espacios\n",
    "file = \"400finito.txt\"\n",
    "texto = \"\"\n",
    "with open(file, encoding='latin-1') as csvfile:\n",
    "    texto = csvfile.read()\n",
    "    csvfile.seek(0)\n",
    "    lineas = csvfile.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_texto= tokens(texto)\n",
    "texto_fd = nltk.FreqDist(tokens_texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lineas) == 400*16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6400"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "400*16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Por categoría (n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=16 #numero de categorías\n",
    "masc = '1' #masculino\n",
    "fem = '2' #femenino\n",
    "data_linea = {i:[] for i in range(1,n+1)} #Todos los datos por categoría\n",
    "data_linea_raw = {i:[] for i in range(1,n+1)} #Todos los datos por categoría texto\n",
    "j=0\n",
    "code_sexo= {'1':'masculino', '2':'femenino'}\n",
    "code_colegio = {'1':'publico', '2':'pagado', '3':'subencionado'}\n",
    "for i,linea in enumerate(lineas):\n",
    "    if i%n==0:\n",
    "        j=0\n",
    "    #code = linea.split()[0][0]\n",
    "    #if code == fem:\n",
    "    data_linea[j+1].append(tokens(linea)) #tokens por linea\n",
    "    data_linea_raw[j+1].append(re.sub(r'\\d+', '', linea)) #texto por linea\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_linea[16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cat ={i:[] for i in range(1,n+1)}  #tokens para FreqDist\n",
    "for categoria in data_linea:\n",
    "    data_i = [] #tokens por categoría\n",
    "    for linea in data_linea[categoria]:\n",
    "        data_i+=linea\n",
    "    data_cat[categoria] += data_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqdist_cat = {i:[] for i in range(1,n+1)} #Frecuencias de tokens\n",
    "for cat in data_cat:\n",
    "    freqdist_cat[cat] = nltk.FreqDist(data_cat[cat])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import ngrams\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame para cada categoría con bigramas para plotear grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cat_ngrams = {} #ngrams para cada categoría\n",
    "data_cat_fd = {} #FreqDist para cada categoria\n",
    "for cat in data_cat:\n",
    "    n_grams = ngrams(data_cat[cat], 2)\n",
    "    data_cat_ngrams[cat] = [ ' '.join(grams) for grams in n_grams]\n",
    "    data_cat_fd[cat] = nltk.FreqDist(data_cat_ngrams[cat])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame para cada categoría con bigramas para plotear grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cat_fd_dataframe = {} #dataframe con frecuencias de bigrams para cada categoria\n",
    "for k in data_cat_fd:\n",
    "    fd_sorted = {k: v for k, v in sorted(data_cat_fd[k].items(), key=lambda item: item[1], reverse=True)}\n",
    "    keys = list(fd_sorted.keys())\n",
    "    freq = list(fd_sorted.values())\n",
    "    origen = [bigram.split()[0] for bigram in keys]\n",
    "    destino = [bigram.split()[1] for bigram in keys]\n",
    "    #n = list(data_cat_fd[k].values())\n",
    "    data = {\n",
    "        \"origen\": origen,\n",
    "        \"destino\": destino,\n",
    "        \"n\": freq\n",
    "    }\n",
    "    data_cat_fd_dataframe[k] = pd.DataFrame(data) #dataframe por categoria para crear grafo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_cat_fd_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_categorias = [\n",
    "    \"Partes del cuerpo\",\n",
    "    \"La ropa\",\n",
    "    \"Partes de la casa (sin los muebles)\",\n",
    "    \"Los muebles\",\n",
    "    \"Alimentos y bebidas\",\n",
    "    \"Objetos colocados encima de la mesa para la comida\",\n",
    "    \"La cocina y sus utensilios\",\n",
    "    \"La escuela\",\n",
    "    \"Calefacción, iluminación y medios para airear un recinto\",\n",
    "    \"La ciudad\",\n",
    "    \"El campo\",\n",
    "    \"Medios de transporte\",\n",
    "    \"Trabajos del campo y del jardín\",\n",
    "    \"Animales\",\n",
    "    \"Juegos y distracciones\",\n",
    "    \"Profesiones y oficio\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Partes_del_cuerpo'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Partes del cuerpo\".replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for centro in data_cat_fd:\n",
    "    origen_ = list(data_cat_fd_dataframe[centro].origen)\n",
    "    destino_ = list(data_cat_fd_dataframe[centro].destino)\n",
    "    n_ = list(data_cat_fd_dataframe[centro].n)\n",
    "    nombre = nombres_categorias[centro-1].replace(' ', '_')\n",
    "    dot = Digraph(name=nombre, comment='Grafo dirigido palabra por categoria')\n",
    "    for o,d,i in zip(origen_, destino_, n_):\n",
    "        #if i>5:\n",
    "        dot.edge(o, d, label=str(i), weight=str(i))\n",
    "    #dot.attr(bgcolor='purple:pink', label='Categoría 1', fontcolor='white')\n",
    "    dot.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
